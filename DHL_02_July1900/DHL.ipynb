{"cells":[{"cell_type":"code","metadata":{"source_hash":"abfa29c7","execution_start":1719938923967,"execution_millis":76,"deepnote_to_be_reexecuted":false,"cell_id":"09355f5e053640898100ff8241780500","deepnote_cell_type":"code"},"source":"# !pip install cplex\n# print(cplex.__version__)\n\n\n# !pip install docplex==2.27.239\n#!pip install openpyxl","block_group":"83a4818cd751499f8082648b310df8e8","execution_count":1,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"a70a7fd7","execution_start":1719938923968,"execution_millis":551,"deepnote_to_be_reexecuted":false,"cell_id":"4f1c5131e1b64d1fb46ed36943a087dc","deepnote_cell_type":"code"},"source":"# The module 'cplex' is not installed in the current environment. Let's switch to 'docplex', which is more commonly used for optimization modeling.\n\nimport pandas as pd\nfrom docplex.mp.model import Model\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nfrom datetime import datetime, timedelta, date, time\nimport math\nimport cplex\nimport json\n\nimport os\nos.environ['ILOG_LICENSE_FILE'] = 'D:\\Cplex\\python'","block_group":"2da4c47ccfbc4829b71202c9c3de3377","execution_count":2,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"39ee6ddd37b0417cbff83dd6169e5115","deepnote_cell_type":"markdown"},"source":"# Read data","block_group":"f2e86642b2414efa8e5129a2f02e1821"},{"cell_type":"code","metadata":{"source_hash":"1d2bf2ca","execution_start":1719938924521,"execution_millis":4190,"deepnote_to_be_reexecuted":false,"cell_id":"2bbfeba53fc949d9b2b27e2c0126676e","deepnote_cell_type":"code"},"source":"d_path = '2024-04-25_OSRM_Truck_Distanzen+Fahrtzeiten_PZ_x_PZ.xlsx'    # Excel that contains the distance and time between service centers\nsb_path = '2024-04-25_OR Praktikum_RWTH Aachen_WBeh_AuftrÃ¤ge.xlsx'  # Excel that contains the information of each Swapbodies and where it needs to go \ni_path = '2024-04-25_OR Praktikum_RWTH Aachen_Inputs.xlsx'       # Excel that contains the sorting capacity of each service center\n\n# Read data from the Excel files into pandas DataFrames\ndf_times = pd.read_excel(d_path)\ndf_swapbodies = pd.read_excel(sb_path)\ndf_input = pd.read_excel(i_path, header=1, usecols=lambda x: 'Unnamed' not in x).dropna(axis='rows')\n\n","block_group":"7e2961bf5d7342c39580fd8b49c11dfa","execution_count":3,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"8ee5ffce","execution_start":1719938928725,"execution_millis":64,"deepnote_to_be_reexecuted":false,"cell_id":"1a956489d82f4e82967d3184f37b54df","deepnote_cell_type":"code"},"source":"# Raname columns of excel files , simulating macros\nclass Rename:\n    SORTING_FACILITY = \"Sortierleistung [Sdg je h]\"\n    SWAPBODY = \"id\"\n    PZ = 'PZA_GNR'\n    PZA = \"Origin_ID\"\n    PZE = \"Destination_ID\"\n    QUANTITY = \"Sendungsmenge\"\n    TIME = \"OSRM_time [sek]\"\n    PICK_UP_TIME = \"geplantes_beladeende\"\n    SORTING_DOOR = \"Entladeleistung je Entladeband (Tor) je Stunde\"\n    SHIFT_END = \"Auflegeende (=Sortierschluss/ PZE Sorter Cutoff)\"\n    SHIFT_BEGIN = \"Schichtbeginn\"\n\ndf_times[Rename.TIME] = df_times[Rename.TIME]/3600\ndf_swapbodies.rename(columns = {\"quelle_agnr\":\"Origin_ID\"}, inplace = True)\ndf_swapbodies.rename(columns = {\"senke_agnr\":\"Destination_ID\"}, inplace = True)\n\n# Convert the DateTime column to datetime format\ndf_swapbodies[Rename.PICK_UP_TIME] = pd.to_datetime(df_swapbodies[Rename.PICK_UP_TIME], format='%d/%m/%Y %H:%M').dt.time\n\n","block_group":"e9d9ba2162fe46fba95df02be4dc2991","execution_count":4,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"f5539101f0054d1688d75e3b58e1e474","deepnote_cell_type":"markdown"},"source":"# Amount of data loaded into the model","block_group":"4b2076bc1695493fb69ff03f83b62d8a"},{"cell_type":"code","metadata":{"source_hash":"de1e412","execution_start":1719938928736,"execution_millis":78,"deepnote_to_be_reexecuted":false,"cell_id":"57873faff91843c9b5142718517e1607","deepnote_cell_type":"code"},"source":"df_times = df_times.head(200)\ndf_swapbodies = df_swapbodies.head(200)\ndf_input = df_input.head(200)","block_group":"91ff6f40982042f9b5e5aae7260c43f8","execution_count":5,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"bab50bbab30648a9ac208773bbd31e0b","deepnote_cell_type":"markdown"},"source":"# Time Windows // Trying to apply the time window as draw in the diagram","block_group":"e4f310efe81e41e7830a5f4d0b5667c0"},{"cell_type":"code","metadata":{"source_hash":"d176fea1","execution_start":1719938928742,"execution_millis":73,"deepnote_to_be_reexecuted":false,"cell_id":"fbab3996cef94502b821c14e0f028af8","deepnote_cell_type":"code"},"source":"from datetime import time\n\ndef add_float_to_time(time_obj, float_hours):\n    \"\"\"\n    Add a float number of hours to a given time object.\n\n    Args:\n    - time_obj (datetime.time): The original time object to add hours to.\n    - float_hours (float): The number of hours to add, as a float.\n\n    Returns:\n    - datetime.time: A new time object representing the updated time after adding hours.\n    \"\"\"\n\n    # Convert time_obj to the number of seconds since midnight\n    total_seconds = time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second\n    \n    # Convert float_hours to seconds\n    added_seconds = round(float_hours * 3600)\n    \n    # Add the added_seconds to total_seconds\n    new_total_seconds = total_seconds + added_seconds\n    \n    # Calculate the new hours, minutes, and seconds\n    new_hours = (new_total_seconds // 3600) % 24\n    new_minutes = (new_total_seconds % 3600) // 60\n    new_seconds = new_total_seconds % 60\n    \n    # Create a new time object\n    new_time_obj = time(new_hours, new_minutes, new_seconds)\n    \n    return new_time_obj\n","block_group":"df48e4241ed54d65af43ed64a8c00b08","execution_count":6,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"c9128b849355444396ea14896a18c429","deepnote_cell_type":"markdown"},"source":"# E + 1 Function","block_group":"00434255a8304e9095419db2e288bfa5"},{"cell_type":"code","metadata":{"source_hash":"a77aa1d3","execution_start":1719938928751,"execution_millis":64,"deepnote_to_be_reexecuted":false,"cell_id":"a5cd489fefb04527b523d3cfacc2ebeb","deepnote_cell_type":"code"},"source":"def calculate_hour_range(start_time, end_time):\n    \"\"\"\n    Calculate the number of hours between two time points.\n\n    Args:\n        start_time (datetime.time): Start time.\n        end_time (datetime.time): End time.\n\n    Returns:\n        float: Number of hours between start_time and end_time.\n    \"\"\"\n    \n    # Convert datetime.time to datetime.datetime to facilitate subtraction\n    start_datetime = datetime.combine(date.today(), start_time)\n    end_datetime = datetime.combine(date.today(), end_time)\n    \n    # Calculate timedelta\n    if end_datetime >= start_datetime:\n        # Calculate hours when end time is on the same day\n        hour_range = (end_datetime - start_datetime).total_seconds() / 3600.0\n    else:\n        # Handle case where end time is on the next day (assuming it's a 24-hour cycle)\n        hour_range = (timedelta(days=1) - (start_datetime - end_datetime)).total_seconds() / 3600.0\n    \n    return hour_range\n","block_group":"7eddc27a22fd4effb733a33a03ffdeae","execution_count":7,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"6e15647b","execution_start":1719938928762,"execution_millis":53,"deepnote_to_be_reexecuted":false,"cell_id":"ba8ca5bc7e4842aba3dc39cd6728e7ff","deepnote_cell_type":"code"},"source":"\nimport json\nimport math\n\ndef eplus(df_swapbodies, df_times, df_input):\n    \"\"\"\n    Process swap body data to determine which swap bodies and in which trajectory achieve E + 1.\n\n    Args:\n        df_swapbodies (DataFrame): DataFrame containing swap body information.\n        df_times (DataFrame): DataFrame containing time information.\n        df_input (DataFrame): DataFrame containing input data.\n\n    Returns:\n        None\n    \"\"\"\n    \n    # Initialize the nested dictionary without specifying values\n    eplus_output_dict = {}\n\n    # Loop through each swap body in df_swapbodies\n    for i in range(len(df_swapbodies)):\n        swapbody_id = str(df_swapbodies.loc[i, Rename.SWAPBODY])  # Convert to string if necessary\n\n        # Calculate the time when a swap body is ready (pick up) at PZA\n        pze_value = df_swapbodies.loc[i, Rename.PZE]\n        \n        # Check if PZE value exists in input PZ data\n        if pze_value in df_input[Rename.PZ].values:\n            search_pz = pze_value\n            pze_sb = df_swapbodies[df_swapbodies[Rename.PZE] == search_pz]\n\n            if not pze_sb.empty:\n                pick_up_time = pze_sb.iloc[0][Rename.PICK_UP_TIME]  # Get pick-up time from swap body data\n\n                # Calculate arrival time of swap body at PZE\n                origin_id = df_swapbodies.loc[i, Rename.PZA]\n                destination_id = df_swapbodies.loc[i, Rename.PZE]\n\n                # Find matching time data for origin and destination IDs\n                match_pz_d = df_times[(df_times[Rename.PZA] == origin_id) & (df_times[Rename.PZE] == destination_id)]\n\n                if not match_pz_d.empty:\n                    match_pz_time = match_pz_d.iloc[0][Rename.TIME]  # Get travel time between PZA and PZE\n\n                    arr_time = add_float_to_time(pick_up_time, match_pz_time)\n\n                    match_pz_inp = df_input[df_input[Rename.PZ] == destination_id]\n\n                    if not match_pz_inp.empty:\n                        match_pz_shift_begin = match_pz_inp.iloc[0][Rename.SHIFT_BEGIN]\n                        match_pz_shift_end = match_pz_inp.iloc[0][Rename.SHIFT_END]\n\n                        # Adjust arrival time if it's before shift begin\n                        if arr_time <= match_pz_shift_begin:\n                            arr_time = match_pz_shift_begin\n\n                        # Calculate available hours within shift time\n                        hours_avail = calculate_hour_range(arr_time, match_pz_shift_end)\n\n                        match_pz_sb = df_swapbodies[(df_swapbodies[Rename.PZA] == origin_id) & (df_swapbodies[Rename.PZE] == destination_id)]\n\n                        if not match_pz_sb.empty:\n                            match_pz_quantity = match_pz_sb.iloc[0][Rename.QUANTITY]\n                            match_pz_sorting = match_pz_inp.iloc[0][Rename.SORTING_DOOR]\n\n                            # Calculate sorting ratio based on quantity and sorting capacity\n                            sorting_ratio = math.ceil(match_pz_quantity / match_pz_sorting)\n\n                            # Check if enough hours available for sorting\n                            hours_avail = hours_avail - sorting_ratio\n                            if hours_avail  >= 0:\n                                eplus_output_dict[swapbody_id] = {\n                                    \"PZA\": origin_id,\n                                    \"PZE\": destination_id,\n                                    \"Arrival Time\": arr_time.strftime('%H:%M'),\n                                    \"Slack Time (hrs)\": round(hours_avail, 2) \n                                }\n                            else:\n                                print(\"Not enough hours available for sorting\")\n                        else:\n                            print(\"No matching swap body found for sorting calculation\")\n                    else:\n                        print(\"No input data found for destination PZ\")\n                else:\n                    print(\"No matching time data found for origin and destination IDs\")\n            else:\n                print(\"No swap body found for PZE:\", pze_value)\n        else:\n            print(\"PZE value not found in input PZ data\")\n\n    # Write output dictionary to JSON file\n    file_path = 'eplusone.json'\n    with open(file_path, 'w') as file:\n        json.dump(eplus_output_dict, file, indent=4)\n","block_group":"4f14c19c91914202bca910b047302506","execution_count":8,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"25631e76","execution_start":1719938928781,"execution_millis":35,"deepnote_to_be_reexecuted":false,"cell_id":"10905edff29746d693135643e376a3af","deepnote_cell_type":"code"},"source":"#Mute CPLEX logs\ndef muteCplexLog(model):\n    model.set_log_stream(None)\n    model.set_error_stream(None)\n    model.set_warning_stream(None)\n    model.set_results_stream(None)","block_group":"03067b9a8bfb4350a8d01e037899e960","execution_count":9,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"ee0ea362","execution_start":1719938928792,"execution_millis":42,"deepnote_to_be_reexecuted":false,"cell_id":"e47c6b7f786a4c5bb3dfe338604d33f7","deepnote_cell_type":"code"},"source":"def solve_transportation_problem(model, df_times, df_swapbodies, df_input, time_weight=1.0, quantity_weight=1.0):\n    \"\"\"\n    Solves a transportation problem using CPLEX.\n\n    Args:\n    - model: CPLEX model instance\n    - df_times: DataFrame containing time data\n    - df_swapbodies: DataFrame containing swap body data\n    - df_input: DataFrame containing input data\n    - time_weight: Weight for time component in objective function\n    - quantity_weight: Weight for quantity component in objective function\n    \"\"\"\n\n    # Extract necessary data from the dataframes\n    swapbodies = df_swapbodies[Rename.SWAPBODY].tolist()\n    pzas = df_swapbodies[Rename.PZA].tolist()\n    pzes = df_swapbodies[Rename.PZE].tolist()\n    quantities = df_swapbodies[Rename.QUANTITY].tolist()\n    \n    # Convert Time from seconds to hours\n    times = df_times.set_index([Rename.PZA, Rename.PZE])[Rename.TIME]   # Assuming TIME is in seconds, convert to hours\n    times = times.to_dict()\n    \n    num_swapbodies = len(swapbodies)\n    \n    # Objective function: combine time and quantity\n    obj = []\n    x = []\n    for i in range(num_swapbodies):\n        pza_coord = pzas[i]\n        pze_coord = pzes[i]\n        time_component = 0\n        if (pza_coord, pze_coord) in times:\n            time = times[(pza_coord, pze_coord)]\n            time_component = time_weight * time\n        quantity_component = quantity_weight * quantities[i]\n        total_component = time_component + quantity_component\n        x.append(model.variables.add(obj=[total_component], lb=[0], ub=[1], types=['B'], names=[f'x_{i}'])[0])\n    \n    model.objective.set_sense(model.objective.sense.minimize)\n    \n    # Constraints: ensure each ID is moved from its PZA to PZE\n    for i in range(num_swapbodies):\n        model.linear_constraints.add(\n            lin_expr=[cplex.SparsePair([x[i]], [1])],\n            senses=['E'], rhs=[1], names=[f'move_{i}']\n        )\n    \n    # Group quantities and sorting capacities by facility\n    facility_quantities = df_swapbodies.groupby(Rename.PZE)[Rename.QUANTITY].sum().to_dict()\n    facility_sorting = df_input.groupby(Rename.PZ)[Rename.SORTING_FACILITY].sum().to_dict()\n    \n    # Constraint: Total quantities of swap bodies at each facility <= Facility's sorting capacity\n    for facility_name, total_quantity in facility_quantities.items():\n        if facility_name in facility_sorting:\n            facility_indices = [k for k in range(num_swapbodies) if pzes[k] == facility_name]\n            if facility_indices:\n                model.linear_constraints.add(\n                    lin_expr=[cplex.SparsePair([x[i] for i in facility_indices], [quantities[i] for i in facility_indices])],\n                    senses=['L'], rhs=[facility_sorting[facility_name]], names=[f'quantity_sorting_facility_{facility_name}']\n                )\n        else:\n            print(f\"Warning: Facility {facility_name} not found in facility_sorting\")\n    \n    # Constraint: Max 2 swapbodies per truck\n    for l in range(num_swapbodies):\n        model.linear_constraints.add(\n            lin_expr=[cplex.SparsePair([x[l]], [1])],\n            senses=['L'], rhs=[2], names=[f'max_ids_per_truck_{l}']\n        )\n\n    # Mute CPLEX log for the transportation problem solving part\n    muteCplexLog(model)\n    \n    # Solve the model\n    model.solve()\n    \n    # Call eplus function to process additional data\n    eplus(df_swapbodies, df_times, df_input)\n    \n    # Print solution\n    if model.solution.is_primal_feasible():\n        print('Objective Value:', model.solution.get_objective_value())\n        # Print solution details if needed\n        # for k in range(num_swapbodies):\n        #     if model.solution.get_values(x[k]) > 0.9:\n        #         print(f'Swap-body {swapbodies[k]} moved from PZA {pzas[k]} to PZE {pzes[k]}')\n    else:\n        print('No feasible solution found.')","block_group":"feb690b5840f46e2ba7c66e0461c8f50","execution_count":10,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"bda3a502101443e3b6ba3abf2d55a1e9","deepnote_cell_type":"text-cell-h1"},"source":"# Running Instances","block_group":"409b72cc207540aaa0cc15c78e65b4ce"},{"cell_type":"code","metadata":{"source_hash":"31af764c","execution_start":1719938928797,"execution_millis":1029,"deepnote_to_be_reexecuted":false,"cell_id":"3fba4bc326244362afcd89bf8187e71b","deepnote_cell_type":"code"},"source":"#Init model and mute CPLEX output\nmodel = cplex.Cplex()\nmuteCplexLog(model)\n\n\nsolve_transportation_problem(model, df_times, df_swapbodies, df_input, time_weight=1, quantity_weight=1)","block_group":"e574b4ff92c74724a832fe6be173a4af","execution_count":11,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Swapbody'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/shared-libs/python3.11/py/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Swapbody'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m cplex\u001b[38;5;241m.\u001b[39mCplex()\n\u001b[1;32m      3\u001b[0m muteCplexLog(model)\n\u001b[0;32m----> 6\u001b[0m \u001b[43msolve_transportation_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_swapbodies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantity_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[10], line 79\u001b[0m, in \u001b[0;36msolve_transportation_problem\u001b[0;34m(model, df_times, df_swapbodies, df_input, time_weight, quantity_weight)\u001b[0m\n\u001b[1;32m     76\u001b[0m model\u001b[38;5;241m.\u001b[39msolve()\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Call eplus function to process additional data\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m \u001b[43meplus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_swapbodies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Print solution\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39msolution\u001b[38;5;241m.\u001b[39mis_primal_feasible():\n","Cell \u001b[0;32mIn[8], line 33\u001b[0m, in \u001b[0;36meplus\u001b[0;34m(df_swapbodies, df_times, df_input)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Loop through each swap body in df_swapbodies\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_swapbodies)):\n\u001b[0;32m---> 33\u001b[0m     swapbody_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mdf_swapbodies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSwapbody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Replace with actual column name\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Calculate the time when a swap body is ready (pick up) at PZA\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     pze_value \u001b[38;5;241m=\u001b[39m df_swapbodies\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPZE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/shared-libs/python3.11/py/lib/python3.11/site-packages/pandas/core/indexing.py:1146\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n","File \u001b[0;32m/shared-libs/python3.11/py/lib/python3.11/site-packages/pandas/core/frame.py:4005\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4002\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[0;32m-> 4005\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4006\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4009\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4010\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4011\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n","File \u001b[0;32m/shared-libs/python3.11/py/lib/python3.11/site-packages/pandas/core/frame.py:4414\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4409\u001b[0m res \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(item)\n\u001b[1;32m   4410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4411\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4412\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[0;32m-> 4414\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4415\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4417\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n","File \u001b[0;32m/shared-libs/python3.11/py/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'Swapbody'"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/53c69ebb-6176-4dcc-894d-d8982cbb3388","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=191c9c86-2871-4134-855d-0821a157bdce' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"cd37132ab9984fd293324544bc0af2d1","deepnote_execution_queue":[]}}