{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pulp as lp\n",
    "from pulp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from the excel sheets.\n",
    "source_df = pd.read_excel(\"Source_facility_info.xlsx\", sheet_name= \"PZA\")\n",
    "destination_df = pd.read_excel(\"Destination_facility_info.xlsx\", sheet_name= \"PZE\")\n",
    "trucking_df = pd.read_excel(\"Trucking_info.xlsx\", sheet_name= \"Truck\")\n",
    "\n",
    "# Convert relevant columns to datetime# Convert start_shift and end_shift to numerical hours and normalize end_shift to handle the next day\n",
    "def normalize_shift_times(row):\n",
    "    start_hour = row['Start of shift'].hour + row['Start of shift'].minute / 60\n",
    "    end_hour = row['End of lay-on'].hour + row['End of lay-on'].minute / 60\n",
    "    if end_hour < start_hour:\n",
    "        end_hour += 24  # normalize end_hour for the next day\n",
    "    return pd.Series([start_hour, end_hour])\n",
    "\n",
    "destination_df[['Start of shift', 'End of lay-on']] = destination_df.apply(normalize_shift_times, axis=1)\n",
    "source_df['planned_end_of_loading'] = pd.to_datetime(source_df['planned_end_of_loading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = lp.LpProblem(\"DHL_Optimization\", lp.LpMinimize)\n",
    "\n",
    "# Defining variables\n",
    "source_list = list(trucking_df['Origin_ID'].unique()[:3])  # Index of PZA\n",
    "destination_list = list(trucking_df['Destination_ID'].unique()[:3])  # Index of PZE\n",
    "routes_list = [(i, j) for i in source_list for j in destination_list if i != j]\n",
    "consignment_list =  [x\n",
    "    for (i, j) in routes_list\n",
    "    for x in source_df[(source_df['Origin_ID'] == i) & (source_df['Destination_ID'] == j)]['id'].values\n",
    "]\n",
    "valid_combinations = [(i, j, k) for (i, j) in routes_list for k in consignment_list if k in source_df[(source_df['Origin_ID'] == i) & (source_df['Destination_ID'] == j)]['id'].values]\n",
    "\n",
    "trucks = range(100)\n",
    "\n",
    "# Decision Variables\n",
    "# X - Whether a truck goes from I to J\n",
    "X = lp.LpVariable.dicts(\"X\", [(i, j, k , l) for (i, j, k) in valid_combinations for l in trucks], cat='Binary')\n",
    "\n",
    "# # Y - Consignment K being carried by K or not\n",
    "# Y = lp.LpVariable.dicts(\"Y\", [(k, l) for k in source_df['id'].unique() for l in trucks], cat='Binary')\n",
    "\n",
    "# Z - From a pool of Trucks, whether a truck is used or not\n",
    "Z = lp.LpVariable.dicts(\"Z\", trucks, cat='Binary')\n",
    "\n",
    "# T - Time of departure of a given truck\n",
    "T = lp.LpVariable.dicts(\"T\", trucks, lowBound=0, cat='Integer')\n",
    "\n",
    "ArrivalDay = lp.LpVariable.dicts(\"ArrivalDay\", trucks, lowBound=0, cat='Integer')  # 0 for same day, 1 for next day, etc.\n",
    "\n",
    "ArrivalTime = lp.LpVariable.dicts(\"ArrivalTime\", [(i, j, k, l) for (i, j, k) in valid_combinations for l in trucks], lowBound=0, upBound=24, cat='Continuous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the objective function: Maximizing the (E+1)th day output and minimizing the distance\n",
    "model += lp.lpSum(ArrivalDay[l] for l in trucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints\n",
    "# 1. Each truck can carry at most 2 consignments\n",
    "for l in trucks:\n",
    "    model += lp.lpSum([X[(i, j, k, l)] for (i, j, k) in valid_combinations]) <= 2 * Z[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Consignment can only be released after the latest release time of the consignments\n",
    "for (i, j, k) in valid_combinations:\n",
    "    release_time = source_df[source_df['id'] == k]['planned_end_of_loading'].dt.hour.values[0]  # Convert to hours\n",
    "    for l in trucks:\n",
    "        model += T[l] >= release_time * X[(i, j, k, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Truck must arrive at the destination within the operational hours\n",
    "\n",
    "for (i, j, k) in valid_combinations:\n",
    "    start_shift = destination_df[destination_df['Destination_ID'] == j]['Start of shift'].values[0]\n",
    "    end_shift = destination_df[destination_df['Destination_ID'] == j]['End of lay-on'].values[0]\n",
    "    travel_time = trucking_df[(trucking_df['Origin_ID'] == i) & (trucking_df['Destination_ID'] == j)]['OSRM_time [sek]'].values[0] / 3600  # Convert to hours\n",
    "    for l in trucks:\n",
    "        # Auxiliary variable to handle modulo operation\n",
    "        multiplier = lp.LpVariable(f\"multiplier_{i}_{j}_{k}_{l}\", cat='Integer')\n",
    "        model += ArrivalTime[(i, j, k, l)] == (T[l] + travel_time * X[(i, j, k, l)] + 24 * ArrivalDay[l]) - 24 * multiplier\n",
    "        model += ArrivalTime[(i, j, k, l)] >= start_shift\n",
    "        model += ArrivalTime[(i, j, k, l)] <= end_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Each consignment must be assigned to exactly one truck\n",
    "for k in consignment_list:\n",
    "    model += lp.lpSum([X[(i, j, k, l)] for (i, j) in routes_list for l in trucks if (i, j, k) in valid_combinations]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Flow conservation: If a truck leaves a source, it must go to one destination\n",
    "for l in trucks:\n",
    "    for i in source_list:\n",
    "        for k in consignment_list:\n",
    "            model += lp.lpSum([X[(i, j, k, l)] for j in destination_list if j != i  if (i, j, k) in valid_combinations]) == Z[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Sorting Capacity: Each PZE should have enough capacity to accomodate all the incoming trucks\n",
    "# date_chosen = '2024-04-16'\n",
    "destination_df['Working hours'] = destination_df['End of lay-on'] - destination_df['Start of shift']\n",
    "for j in destination_list:\n",
    "    model += lp.lpSum([X[(i, j, k, l)] * source_df[source_df['id'] == k]['Consignment quantity'].values[0]\n",
    "                      for i in source_list if j != i for k in consignment_list for l in trucks if (i, j, k) in valid_combinations]) <= destination_df[destination_df['Destination_ID'] == j]['Working hours'].values[0] * destination_df[destination_df['Destination_ID'] == j]['Sorting capacity'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model\n",
    "model.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value(model.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"X_('01.1.1.PZ',_'04.1.1.PZ',_7791768,_97)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7791769,_97)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7791773,_58)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7801226,_33)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7801227,_16)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7801229,_1)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7916247,_97)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7916248,_97)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7916250,_50)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7920338,_5)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7942917,_22)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7942917,_94)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7942917,_97)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7942918,_32)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7942919,_44)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7943959,_67)\": 1.0, \"X_('01.1.1.PZ',_'04.1.1.PZ',_7943960,_64)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7791652,_67)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7791655,_30)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7801292,_53)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7801294,_93)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7916311,_67)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7916312,_75)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7916314,_97)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7920463,_79)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7920464,_58)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7920465,_26)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7920465,_39)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7942954,_50)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7942955,_99)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7942956,_5)\": 1.0, \"X_('01.1.1.PZ',_'08.1.1.PZ',_7943995,_82)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7722435,_61)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7740142,_3)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7740142,_86)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7740145,_51)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7740146,_97)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7907964,_60)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7907965,_92)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7907966,_61)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7907967,_67)\": 1.0, \"X_('04.1.1.PZ',_'01.1.1.PZ',_7927734,_69)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7722384,_4)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7722385,_88)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7722386,_16)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7722388,_61)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7740085,_31)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7740087,_14)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7740087,_88)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7907887,_6)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7927786,_14)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7927786,_61)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7927787,_16)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7927787,_78)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7927787,_99)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7927789,_38)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7934258,_74)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7941819,_22)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7941822,_61)\": 1.0, \"X_('04.1.1.PZ',_'08.1.1.PZ',_7941823,_58)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7709632,_50)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7709633,_78)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7709634,_75)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7709635,_1)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7814477,_50)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7814478,_43)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7814481,_14)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7916466,_50)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7916467,_50)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7925727,_41)\": 1.0, \"X_('08.1.1.PZ',_'01.1.1.PZ',_7939126,_58)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7709574,_89)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7814539,_22)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7814540,_51)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7916361,_4)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7916361,_58)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7916362,_81)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7916364,_68)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7925772,_99)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7939132,_35)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7945750,_39)\": 1.0, \"X_('08.1.1.PZ',_'04.1.1.PZ',_7945750,_41)\": 1.0, 'Z_33': 1.0, 'Z_4': 1.0, 'Z_53': 1.0, 'Z_68': 1.0, 'Z_86': 1.0}\n"
     ]
    }
   ],
   "source": [
    "solution = {}\n",
    "for var in model.variables():\n",
    "    if var.varValue == 1:\n",
    "        solution[var.name] = var.varValue\n",
    "print(solution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
