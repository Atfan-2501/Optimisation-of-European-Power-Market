{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"09355f5e053640898100ff8241780500","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":76,"execution_start":1719938923967,"source_hash":"abfa29c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: cplex in d:\\analytics project\\dhl_02_july1900\\dhl_02_july1900\\.venv\\lib\\site-packages (22.1.1.2)\n","22.1.1.0\n","Collecting docplex==2.27.239\n","  Downloading docplex-2.27.239.tar.gz (635 kB)\n","     ---------------------------------------- 0.0/635.6 kB ? eta -:--:--\n","     ----- --------------------------------- 92.2/635.6 kB 2.6 MB/s eta 0:00:01\n","     ------------ ------------------------- 204.8/635.6 kB 2.5 MB/s eta 0:00:01\n","     ---------------------- --------------- 368.6/635.6 kB 2.6 MB/s eta 0:00:01\n","     ----------------------------- -------- 501.8/635.6 kB 2.9 MB/s eta 0:00:01\n","     -------------------------------------  634.9/635.6 kB 2.9 MB/s eta 0:00:01\n","     -------------------------------------- 635.6/635.6 kB 2.7 MB/s eta 0:00:00\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Installing backend dependencies: started\n","  Installing backend dependencies: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: six in d:\\analytics project\\dhl_02_july1900\\dhl_02_july1900\\.venv\\lib\\site-packages (from docplex==2.27.239) (1.16.0)\n","Building wheels for collected packages: docplex\n","  Building wheel for docplex (pyproject.toml): started\n","  Building wheel for docplex (pyproject.toml): finished with status 'done'\n","  Created wheel for docplex: filename=docplex-2.27.239-py3-none-any.whl size=674557 sha256=e56780b87e93a99b243d092f206a726359655419ddfbcc62dfa7f72f4b015aa9\n","  Stored in directory: c:\\users\\ashle\\appdata\\local\\pip\\cache\\wheels\\8f\\b9\\9b\\33ad7127872a733fb506e6c443194d28fb83888ac2879c16f6\n","Successfully built docplex\n","Installing collected packages: docplex\n","Successfully installed docplex-2.27.239\n","Collecting openpyxl\n","  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n","Collecting et-xmlfile (from openpyxl)\n","  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n","Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n","   ---------------------------------------- 0.0/250.9 kB ? eta -:--:--\n","   -------------- ------------------------- 92.2/250.9 kB 2.6 MB/s eta 0:00:01\n","   ------------------------------- -------- 194.6/250.9 kB 2.4 MB/s eta 0:00:01\n","   ---------------------------------------- 250.9/250.9 kB 2.2 MB/s eta 0:00:00\n","Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: et-xmlfile, openpyxl\n","Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n"]}],"source":["!pip install cplex\n","import cplex\n","print(cplex.__version__)\n","\n","\n","!pip install docplex==2.27.239\n","!pip install openpyxl"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"4f1c5131e1b64d1fb46ed36943a087dc","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":551,"execution_start":1719938923968,"source_hash":"a70a7fd7"},"outputs":[],"source":["# The module 'cplex' is not installed in the current environment. Let's switch to 'docplex', which is more commonly used for optimization modeling.\n","\n","import pandas as pd\n","# from docplex.mp.model import Model\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","from datetime import datetime, timedelta, date, time\n","import math\n","import cplex\n","import json\n","\n","import os\n","os.environ['ILOG_LICENSE_FILE'] = 'D:\\Cplex\\python'"]},{"cell_type":"markdown","metadata":{"cell_id":"39ee6ddd37b0417cbff83dd6169e5115","deepnote_cell_type":"markdown"},"source":["# Read data"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"2bbfeba53fc949d9b2b27e2c0126676e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4190,"execution_start":1719938924521,"source_hash":"1d2bf2ca"},"outputs":[],"source":["d_path = '2024-04-25_OSRM_Truck_Distanzen+Fahrtzeiten_PZ_x_PZ.xlsx'    # Excel that contains the distance and time between service centers\n","sb_path = '2024-04-25_OR Praktikum_RWTH Aachen_WBeh_AuftrÃ¤ge.xlsx'  # Excel that contains the information of each Swapbodies and where it needs to go \n","i_path = '2024-04-25_OR Praktikum_RWTH Aachen_Inputs.xlsx'       # Excel that contains the sorting capacity of each service center\n","\n","# Read data from the Excel files into pandas DataFrames\n","df_times = pd.read_excel(d_path)\n","df_swapbodies = pd.read_excel(sb_path)\n","df_input = pd.read_excel(i_path, header=1, usecols=lambda x: 'Unnamed' not in x).dropna(axis='rows')\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"1a956489d82f4e82967d3184f37b54df","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":64,"execution_start":1719938928725,"source_hash":"8ee5ffce"},"outputs":[],"source":["# Raname columns of excel files , simulating macros\n","class Rename:\n","    SORTING_FACILITY = \"Sortierleistung [Sdg je h]\"\n","    SWAPBODY = \"id\"\n","    PZ = 'PZA_GNR'\n","    PZA = \"Origin_ID\"\n","    PZE = \"Destination_ID\"\n","    QUANTITY = \"Sendungsmenge\"\n","    TIME = \"OSRM_time [sek]\"\n","    PICK_UP_TIME = \"geplantes_beladeende\"\n","    SORTING_DOOR = \"Entladeleistung je Entladeband (Tor) je Stunde\"\n","    SHIFT_END = \"Auflegeende (=Sortierschluss/ PZE Sorter Cutoff)\"\n","    SHIFT_BEGIN = \"Schichtbeginn\"\n","\n","df_times[Rename.TIME] = df_times[Rename.TIME]/3600\n","df_swapbodies.rename(columns = {\"quelle_agnr\":\"Origin_ID\"}, inplace = True)\n","df_swapbodies.rename(columns = {\"senke_agnr\":\"Destination_ID\"}, inplace = True)\n","\n","# Convert the DateTime column to datetime format\n","df_swapbodies[Rename.PICK_UP_TIME] = pd.to_datetime(df_swapbodies[Rename.PICK_UP_TIME], format='%d/%m/%Y %H:%M').dt.time\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["0      13:00:00\n","1      17:30:00\n","2      18:00:00\n","3      20:15:00\n","4      12:00:00\n","         ...   \n","195    20:15:00\n","196    18:00:00\n","197    20:15:00\n","198    17:50:00\n","199    18:00:00\n","Name: geplantes_beladeende, Length: 200, dtype: object"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df_swapbodies[Rename.PICK_UP_TIME]"]},{"cell_type":"markdown","metadata":{"cell_id":"f5539101f0054d1688d75e3b58e1e474","deepnote_cell_type":"markdown"},"source":["# Amount of data loaded into the model"]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"57873faff91843c9b5142718517e1607","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":78,"execution_start":1719938928736,"source_hash":"de1e412"},"outputs":[],"source":["df_times = df_times.head(200)\n","df_swapbodies = df_swapbodies.head(200)\n","df_input = df_input.head(200)"]},{"cell_type":"markdown","metadata":{"cell_id":"bab50bbab30648a9ac208773bbd31e0b","deepnote_cell_type":"markdown"},"source":["# Time Windows // Trying to apply the time window as drawn in the diagram"]},{"cell_type":"code","execution_count":10,"metadata":{"cell_id":"fbab3996cef94502b821c14e0f028af8","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":73,"execution_start":1719938928742,"source_hash":"d176fea1"},"outputs":[],"source":["from datetime import time\n","\n","def add_float_to_time(time_obj, float_hours):\n","    \"\"\"\n","    Add a float number of hours to a given time object.\n","\n","    Args:\n","    - time_obj (datetime.time): The original time object to add hours to.\n","    - float_hours (float): The number of hours to add, as a float.\n","\n","    Returns:\n","    - datetime.time: A new time object representing the updated time after adding hours.\n","    \"\"\"\n","\n","    # Convert time_obj to the number of seconds since midnight\n","    total_seconds = time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second\n","    \n","    # Convert float_hours to seconds\n","    added_seconds = round(float_hours * 3600)\n","    \n","    # Add the added_seconds to total_seconds\n","    new_total_seconds = total_seconds + added_seconds\n","    \n","    # Calculate the new hours, minutes, and seconds\n","    new_hours = (new_total_seconds // 3600) % 24\n","    new_minutes = (new_total_seconds % 3600) // 60\n","    new_seconds = new_total_seconds % 60\n","    \n","    # Create a new time object\n","    new_time_obj = time(new_hours, new_minutes, new_seconds)\n","    \n","    return new_time_obj\n"]},{"cell_type":"markdown","metadata":{"cell_id":"c9128b849355444396ea14896a18c429","deepnote_cell_type":"markdown"},"source":["# E + 1 Function"]},{"cell_type":"code","execution_count":11,"metadata":{"cell_id":"a5cd489fefb04527b523d3cfacc2ebeb","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":64,"execution_start":1719938928751,"source_hash":"a77aa1d3"},"outputs":[],"source":["def calculate_hour_range(start_time, end_time):\n","    \"\"\"\n","    Calculate the number of hours between two time points.\n","\n","    Args:\n","        start_time (datetime.time): Start time.\n","        end_time (datetime.time): End time.\n","\n","    Returns:\n","        float: Number of hours between start_time and end_time.\n","    \"\"\"\n","    \n","    # Convert datetime.time to datetime.datetime to facilitate subtraction\n","    start_datetime = datetime.combine(date.today(), start_time)\n","    end_datetime = datetime.combine(date.today(), end_time)\n","    \n","    # Calculate timedelta\n","    if end_datetime >= start_datetime:\n","        # Calculate hours when end time is on the same day\n","        hour_range = (end_datetime - start_datetime).total_seconds() / 3600.0\n","    else:\n","        # Handle case where end time is on the next day (assuming it's a 24-hour cycle)\n","        hour_range = (timedelta(days=1) - (start_datetime - end_datetime)).total_seconds() / 3600.0\n","    \n","    return hour_range\n"]},{"cell_type":"code","execution_count":12,"metadata":{"cell_id":"ba8ca5bc7e4842aba3dc39cd6728e7ff","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":53,"execution_start":1719938928762,"source_hash":"6e15647b"},"outputs":[],"source":["\n","import json\n","import math\n","\n","def eplus(df_swapbodies, df_times, df_input):\n","    \"\"\"\n","    Process swap body data to determine which swap bodies and in which trajectory achieve E + 1.\n","\n","    Args:\n","        df_swapbodies (DataFrame): DataFrame containing swap body information.\n","        df_times (DataFrame): DataFrame containing time information.\n","        df_input (DataFrame): DataFrame containing input data.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    \n","    # Initialize the nested dictionary without specifying values\n","    eplus_output_dict = {}\n","\n","    # Loop through each swap body in df_swapbodies\n","    for i in range(len(df_swapbodies)):\n","        swapbody_id = str(df_swapbodies.loc[i, Rename.SWAPBODY])  # Convert to string if necessary\n","\n","        # Calculate the time when a swap body is ready (pick up) at PZA\n","        pze_value = df_swapbodies.loc[i, Rename.PZE]\n","        \n","        # Check if PZE value exists in input PZ data\n","        if pze_value in df_input[Rename.PZ].values:\n","            search_pz = pze_value\n","            pze_sb = df_swapbodies[df_swapbodies[Rename.PZE] == search_pz]\n","\n","            if not pze_sb.empty:\n","                pick_up_time = pze_sb.iloc[0][Rename.PICK_UP_TIME]  # Get pick-up time from swap body data\n","\n","                # Calculate arrival time of swap body at PZE\n","                origin_id = df_swapbodies.loc[i, Rename.PZA]\n","                destination_id = df_swapbodies.loc[i, Rename.PZE]\n","\n","                # Find matching time data for origin and destination IDs\n","                match_pz_d = df_times[(df_times[Rename.PZA] == origin_id) & (df_times[Rename.PZE] == destination_id)]\n","\n","                if not match_pz_d.empty:\n","                    match_pz_time = match_pz_d.iloc[0][Rename.TIME]  # Get travel time between PZA and PZE\n","\n","                    arr_time = add_float_to_time(pick_up_time, match_pz_time)\n","\n","                    match_pz_inp = df_input[df_input[Rename.PZ] == destination_id]\n","\n","                    if not match_pz_inp.empty:\n","                        match_pz_shift_begin = match_pz_inp.iloc[0][Rename.SHIFT_BEGIN]\n","                        match_pz_shift_end = match_pz_inp.iloc[0][Rename.SHIFT_END]\n","\n","                        # Adjust arrival time if it's before shift begin\n","                        if arr_time <= match_pz_shift_begin:\n","                            arr_time = match_pz_shift_begin\n","\n","                        # Calculate available hours within shift time\n","                        hours_avail = calculate_hour_range(arr_time, match_pz_shift_end)\n","\n","                        match_pz_sb = df_swapbodies[(df_swapbodies[Rename.PZA] == origin_id) & (df_swapbodies[Rename.PZE] == destination_id)]\n","\n","                        if not match_pz_sb.empty:\n","                            match_pz_quantity = match_pz_sb.iloc[0][Rename.QUANTITY]\n","                            match_pz_sorting = match_pz_inp.iloc[0][Rename.SORTING_DOOR]\n","\n","                            # Calculate sorting ratio based on quantity and sorting capacity\n","                            sorting_ratio = math.ceil(match_pz_quantity / match_pz_sorting)\n","\n","                            # Check if enough hours available for sorting\n","                            hours_avail = hours_avail - sorting_ratio\n","                            if hours_avail  >= 0:\n","                                eplus_output_dict[swapbody_id] = {\n","                                    \"PZA\": origin_id,\n","                                    \"PZE\": destination_id,\n","                                    \"Arrival Time\": arr_time.strftime('%H:%M'),\n","                                    \"Slack Time (hrs)\": round(hours_avail, 2) \n","                                }\n","                            else:\n","                                print(\"Not enough hours available for sorting\")\n","                        else:\n","                            print(\"No matching swap body found for sorting calculation\")\n","                    else:\n","                        print(\"No input data found for destination PZ\")\n","                else:\n","                    print(\"No matching time data found for origin and destination IDs\")\n","            else:\n","                print(\"No swap body found for PZE:\", pze_value)\n","        else:\n","            print(\"PZE value not found in input PZ data\")\n","\n","    # Write output dictionary to JSON file\n","    file_path = 'eplusone.json'\n","    with open(file_path, 'w') as file:\n","        json.dump(eplus_output_dict, file, indent=4)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"10905edff29746d693135643e376a3af","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":35,"execution_start":1719938928781,"source_hash":"25631e76"},"outputs":[],"source":["#Mute CPLEX logs\n","def muteCplexLog(model):\n","    model.set_log_stream(None)\n","    model.set_error_stream(None)\n","    model.set_warning_stream(None)\n","    model.set_results_stream(None)"]},{"cell_type":"code","execution_count":14,"metadata":{"cell_id":"e47c6b7f786a4c5bb3dfe338604d33f7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":42,"execution_start":1719938928792,"source_hash":"ee0ea362"},"outputs":[],"source":["def solve_transportation_problem(model, df_times, df_swapbodies, df_input, time_weight=1.0, quantity_weight=1.0):\n","    \"\"\"\n","    Solves a transportation problem using CPLEX.\n","\n","    Args:\n","    - model: CPLEX model instance\n","    - df_times: DataFrame containing time data\n","    - df_swapbodies: DataFrame containing swap body data\n","    - df_input: DataFrame containing input data\n","    - time_weight: Weight for time component in objective function\n","    - quantity_weight: Weight for quantity component in objective function\n","    \"\"\"\n","\n","    # Extract necessary data from the dataframes\n","    swapbodies = df_swapbodies[Rename.SWAPBODY].tolist()\n","    pzas = df_swapbodies[Rename.PZA].tolist()\n","    pzes = df_swapbodies[Rename.PZE].tolist()\n","    quantities = df_swapbodies[Rename.QUANTITY].tolist()\n","    \n","    # Convert Time from seconds to hours\n","    times = df_times.set_index([Rename.PZA, Rename.PZE])[Rename.TIME]   # Assuming TIME is in seconds, convert to hours\n","    times = times.to_dict()\n","    \n","    num_swapbodies = len(swapbodies)\n","    \n","    # Objective function: combine time and quantity\n","    obj = []\n","    x = []\n","    for i in range(num_swapbodies):\n","        pza_coord = pzas[i]\n","        pze_coord = pzes[i]\n","        time_component = 0\n","        if (pza_coord, pze_coord) in times:\n","            time = times[(pza_coord, pze_coord)]\n","            time_component = time_weight * time\n","        quantity_component = quantity_weight * quantities[i]\n","        total_component = time_component + quantity_component\n","        x.append(model.variables.add(obj=[total_component], lb=[0], ub=[1], types=['B'], names=[f'x_{i}'])[0])\n","    \n","    model.objective.set_sense(model.objective.sense.minimize)\n","    \n","    # Constraints: ensure each ID is moved from its PZA to PZE\n","    for i in range(num_swapbodies):\n","        model.linear_constraints.add(\n","            lin_expr=[cplex.SparsePair([x[i]], [1])],\n","            senses=['E'], rhs=[1], names=[f'move_{i}']\n","        )\n","    \n","    # Group quantities and sorting capacities by facility\n","    facility_quantities = df_swapbodies.groupby(Rename.PZE)[Rename.QUANTITY].sum().to_dict()\n","    facility_sorting = df_input.groupby(Rename.PZ)[Rename.SORTING_FACILITY].sum().to_dict()\n","    \n","    # Constraint: Total quantities of swap bodies at each facility <= Facility's sorting capacity\n","    for facility_name, total_quantity in facility_quantities.items():\n","        if facility_name in facility_sorting:\n","            facility_indices = [k for k in range(num_swapbodies) if pzes[k] == facility_name]\n","            if facility_indices:\n","                model.linear_constraints.add(\n","                    lin_expr=[cplex.SparsePair([x[i] for i in facility_indices], [quantities[i] for i in facility_indices])],\n","                    senses=['L'], rhs=[facility_sorting[facility_name]], names=[f'quantity_sorting_facility_{facility_name}']\n","                )\n","        else:\n","            print(f\"Warning: Facility {facility_name} not found in facility_sorting\")\n","    \n","    # Constraint: Max 2 swapbodies per truck\n","    for l in range(num_swapbodies):\n","        model.linear_constraints.add(\n","            lin_expr=[cplex.SparsePair([x[l]], [1])],\n","            senses=['L'], rhs=[2], names=[f'max_ids_per_truck_{l}']\n","        )\n","\n","    # Mute CPLEX log for the transportation problem solving part\n","    muteCplexLog(model)\n","    \n","    # Solve the model\n","    model.solve()\n","    \n","    # Call eplus function to process additional data\n","    eplus(df_swapbodies, df_times, df_input)\n","    \n","    # Print solution\n","    if model.solution.is_primal_feasible():\n","        print('Objective Value:', model.solution.get_objective_value())\n","        # Print solution details if needed\n","        # for k in range(num_swapbodies):\n","        #     if model.solution.get_values(x[k]) > 0.9:\n","        #         print(f'Swap-body {swapbodies[k]} moved from PZA {pzas[k]} to PZE {pzes[k]}')\n","    else:\n","        print('No feasible solution found.')"]},{"cell_type":"markdown","metadata":{"cell_id":"bda3a502101443e3b6ba3abf2d55a1e9","deepnote_cell_type":"text-cell-h1","formattedRanges":[]},"source":["# Running Instances"]},{"cell_type":"code","execution_count":15,"metadata":{"cell_id":"3fba4bc326244362afcd89bf8187e71b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1029,"execution_start":1719938928797,"source_hash":"31af764c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Objective Value: 203207.27511111108\n"]}],"source":["#Init model and mute CPLEX output\n","model = cplex.Cplex()\n","muteCplexLog(model)\n","\n","\n","solve_transportation_problem(model, df_times, df_swapbodies, df_input, time_weight=1, quantity_weight=1)"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=191c9c86-2871-4134-855d-0821a157bdce' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"cd37132ab9984fd293324544bc0af2d1","kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
